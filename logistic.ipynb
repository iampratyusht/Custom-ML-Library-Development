{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e819531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(l):\n",
    "    data=np.array(pd.read_csv(l,delimiter=\",\",skiprows=1))\n",
    "    X = data[:,1:]\n",
    "    Y = data[:,0]\n",
    "    return (X,Y)\n",
    "def split(X,Y,s):\n",
    "    m=X.shape[0]\n",
    "    a=math.ceil(s*m)\n",
    "    return(X[:a],Y[:a],X[a:],Y[a:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7552c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X,w,b):\n",
    "    return  1 / (1 + np.exp(-(X @ w + b)))    \n",
    "def loss(g,y):\n",
    "    m = X.shape[0]\n",
    "    loss = (-1 / m) * np.sum(y * np.log(g+1e-20))\n",
    "    return loss\n",
    "def gradient_descent(one_hot_encoding,sigmoid,X,Y,classes,alpha,steps):\n",
    "    m, n = X.shape\n",
    "    cost = []\n",
    "    w = np.zeros((n,classes))\n",
    "    b = np.zeros(classes)\n",
    "    y = one_hot_encoding(X,Y,classes)\n",
    "    i_list = []\n",
    "    for i in range(steps+1):\n",
    "        i_list.append(i)\n",
    "        g = sigmoid(X,w,b)\n",
    "        error = g - y\n",
    "        w -= alpha * ((X.T @ error) / m)\n",
    "        b -= alpha * (np.sum(error,axis=0) / m)\n",
    "        cost.append(loss(g,y))\n",
    "        if i % math.ceil(steps/10) == 0:\n",
    "            print(f\"Iteration {i:9d}, Cost: {cost[i]}\")\n",
    "    return w,b, cost,i_list\n",
    "\n",
    "def one_hot_encoding(X,Y,classes):\n",
    "    m, n = X.shape\n",
    "    y_he = np.zeros((m,classes))\n",
    "    for k in range(classes):\n",
    "        y_he[:,k] = np.where(Y == k, 1, 0)    \n",
    "    print(\"1-hot-encoding done\")\n",
    "    return y_he\n",
    "\n",
    "def predict_logistic(X, w, b):\n",
    "    m = X.shape[0]\n",
    "    probabilities = 1 / (1 + np.exp(-(X @ w + b)+1e-100))\n",
    "    predictions = np.argmax(probabilities, axis=1) \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b513dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(classes, y_train,y_predicted):\n",
    "    con_matrix = np.zeros((classes,classes),dtype=int)\n",
    "    for i, k in zip(y_train, y_predicted):\n",
    "        con_matrix[int(i),int(k)] += 1\n",
    "    df = pd.DataFrame(con_matrix)\n",
    "    precision = np.zeros(classes)\n",
    "    recall = np.zeros(classes)\n",
    "    f1 = np.zeros(classes)\n",
    "    for i in range(classes):\n",
    "        t_p = con_matrix[i, i]\n",
    "        f_p = np.sum(con_matrix[:, i]) - t_p\n",
    "        f_n = np.sum(con_matrix[i, :]) - t_p\n",
    "        precision[i] = t_p / (t_p + f_p) if (t_p + f_p) != 0 else 0\n",
    "        recall[i] = t_p / (t_p + f_n) if (t_p + f_n) != 0 else 0\n",
    "        f1[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if (precision[i] + recall[i]) != 0 else 0\n",
    "    f1score = np.mean(f1)\n",
    "    return f1score, df\n",
    "\n",
    "def plot(cost,i_list,alpha,iteration):\n",
    "    plt.plot(i_list,cost,c=\"r\",label =f\"cost \\n alpha={alpha} \\n No. of iteration ={iteration}\")\n",
    "    plt.xlabel(f\"iteration\")\n",
    "    plt.ylabel(\"cost\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_data(X, y,y_pred):\n",
    "    marker_styles = ['o', 's', '^', 'v', 'D','x','+','*','<','>']\n",
    "    fig,axs = plt.subplots(5, 2, figsize=(12, 20), sharey=True)\n",
    "    for i in range(classes):\n",
    "        cls1 = y[:] == i\n",
    "        cls2 = y_pred[:] == i\n",
    "        label_ = \"cls \" + str(i)\n",
    "        axs[i//2,i%2].scatter(X[cls1, 428], X[cls1, 427],c=\"r\", label=\"true\")\n",
    "        axs[i//2,i%2].scatter(X[cls2, 428], X[cls2, 427], marker=marker_styles[i],c=\"b\",s=10,label=\"predicted\")\n",
    "        axs[i//2,i%2].legend(loc=\"upper right\")\n",
    "        axs[i//2,i%2].set_xlabel(f'Feature {i}')\n",
    "    plt.ylabel('class 2')  \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9543d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = load_data(\"Classification_train.csv\")\n",
    "X_new=X/255\n",
    "test_size = 0.7\n",
    "X_train,Y_train,X_cv,Y_cv = split(X_new,Y,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"max in original :{np.max(X)}, min in original :{np.min(X)}\")   \n",
    "print(f\"max in normalized :{np.max(X_new)}, min in original :{np.min(X_new)}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 10\n",
    "alpha = 0.9\n",
    "iteration = 10000\n",
    "print(f\"Alpha: {alpha}, No. of iteration: {iteration}\")\n",
    "w_final, b_final, cost_train,i_list = gradient_descent(one_hot_encoding,sigmoid,X_train, Y_train, classes, alpha, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ff5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(cost_train,i_list,alpha,iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validating\n",
    "y_cv_n = one_hot_encoding(X_cv,Y_cv,classes)\n",
    "print(pd.DataFrame(y_cv_n[:10]))\n",
    "\n",
    "g = sigmoid(X_cv,w_final,b_final)\n",
    "cost_cv = loss(g,y_cv_n)\n",
    "print(f\"cost after cross validating: {cost_cv}\")\n",
    "\n",
    "p_cv = predict_logistic(X_cv, w_final, b_final)\n",
    "print('Train Accuracy: %f'%(np.mean(p_cv == Y_cv) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06aba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score, confusion_matrix = f1score(classes,Y_cv,p_cv)\n",
    "print(f\"f1score: {f1_score}\")\n",
    "print()\n",
    "print(\"confusion_matrix\")\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77582f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X_cv, Y_cv,p_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b50e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "X_test,Y_id=load_data(\"Classification_test.csv\")\n",
    "X=X_test\n",
    "p_test = predict_logistic(X_test, w_final, b_final)\n",
    "np.savetxt('logistic_test_prediction.csv', p_test, delimiter=',', header='Test target', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314360d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
